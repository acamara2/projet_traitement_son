{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformée de Fourier à court terme (dite aussi à fenêtres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "import param\n",
    "import holoviews as hv,panel as pn,param\n",
    "from holoviews.streams import Pipe\n",
    "import time\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "from panel.pane import LaTeX\n",
    "from scipy.io.wavfile import read\n",
    "from IPython.display import Audio\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from urllib.request import urlopen\n",
    "import io\n",
    "import scipy.io as sio\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fftpack\n",
    "from matplotlib.pyplot import imshow as imageplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import wave\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saxo=sio.loadmat('Saxo.mat')\n",
    "Saxo1=Saxo['S']\n",
    "Saxo2=Saxo['S1']\n",
    "temp=np.zeros(913)\n",
    "for k in range(0,913):\n",
    "    temp[k]=Saxo2[k]\n",
    "Saxo2=temp\n",
    "N1=int(len(Saxo1)/3)\n",
    "temp=np.zeros(N1)\n",
    "for k in range(0,N1):\n",
    "    temp[k]=Saxo1[k]\n",
    "sax=temp\n",
    "Fe=44100\n",
    "SonGuitare=\"Guitare.wav\"\n",
    "gui=read(SonGuitare)\n",
    "guit=gui[1]/2**14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse de Fourier consiste à décrire un signal ou un son comme une somme de sinusoides, discrètes ou continue. La commande FFT (Fast Fourier Transform) réalisée par la commande fftpack.fft en python permet de calculer les coefficients de décomposition d'un signal dans une telle base. \n",
    "\n",
    "Est-il pour autant toujours pertinent de décomposer un signal ou un son dans une telle base ? \n",
    "\n",
    "La réponse est : Non, pas toujours. Cette décomposition n'est utile, permettra de manipuler le son de manière efficace que si le son est stationnaire. On peut définir mathématiquement le concept de stationnarité mais pour faire simple, un signal est stationnaire s'il a un comportememnt invariant dans le temps. \n",
    "\n",
    "Prenons le son de saxo suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sax, rate=Fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(width=800,height=300,xaxis=None,yaxis=None)\n",
    "hv.Curve(sax).opts(**options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En dehors du début de l'enregristrement, quel que soit l'endroit où vous zoomer, vous observerez le même motif, la même structure. On dit que le don est stationnaire. \n",
    "\n",
    "Regardons maintenant le son de guitare :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(guit, rate=Fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=40000\n",
    "p2=100000\n",
    "l=2000\n",
    "Extrait1=guit[p1:p1+l]\n",
    "t1=np.arange(p1,p1+l)\n",
    "Extrait2=guit[p2:p2+l]\n",
    "t2=np.arange(p2,p2+l)\n",
    "hv.Curve(guit).opts(width=800)*hv.Curve((t1,Extrait1)).opts(color='red')*hv.Curve((t2,Extrait2)).opts(color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on zoom sur deux parties différentes, on n'obtient pas exactement la même chose, ceci est dû au fait que la guitare ne tient pas toujours la même note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Column(hv.Curve(Extrait1).opts(width=800,color='red'),hv.Curve(Extrait2).opts(width=800,color='green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On dit que le son de guitare n'est pas stationnaire. Une analyse de Fourier sur l'intégralité du son de guitare, n'apporterai pas grand chose. Toutes les fréquences seraient mélangés. En traitement du son, l'immense majoriét des sons ne sont pas stationnaires. C'est pourquoi on effecrue un traitement par morceaux, par tranche, on dira plutôt par fenêtre. L'idée est de découper le son sur des intervalles où il est stationnaire et de calculer la transformée de Fourier sur chacune de ces tranches. \n",
    "\n",
    "On estime que les sons courants sont stationnaires sur des intervalles allant de 20 à 50 ms. Pour un son échantillonné à 44100Hz ça signifie qu'on calcule des transformée de Fourier sur environ \n",
    "$\\frac{44100\\times20}{1000}\\approx 880$ et $\\frac{44100\\times50}{1000}\\approx 2200$ points.\n",
    "\n",
    "Comme la FFT se calcule rapidement pour des longueurs de vecteurs qui sont des puissances de 2 (algorithme encore plus rapide dans ce cas), je vais opter pour la suite pour des \"fenêtres\" de 1024 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Une première TFCT élémentaire, un premier spetrogramme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une Transformée de Fourier à court terme (TFCT) est un tableau de nombres complexes dont chaque colonne contient la transformée de Fourier des différentes fenêtres du signal. Chaque colonne correspond à une fenêtre temporelle, chaque ligne à une \"fréquence\". On ne peut afficher un tableau complexe, la plupart du temps on affiche le module de cette transformée que l'on appelle aussi spectrogramme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFCT1(Son,N):\n",
    "    NS=len(Son)\n",
    "    Nf=int(np.floor(NS/N))\n",
    "    TF=np.zeros((N,Nf),dtype=complex)\n",
    "    for k in range(0,Nf):\n",
    "        d=k*N\n",
    "        f=d+N\n",
    "        TF[:,k]=fftpack.fft(Son[d:f])\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule ici le spectrogramme du son de saxo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1024\n",
    "options2= dict(width=800,height=300,xaxis=None,yaxis=None)\n",
    "TFsax=TFCT1(sax,N)\n",
    "Spectresax=np.abs(TFsax)\n",
    "hv.Image(Spectresax).opts(**options2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici celui du son de guitare :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1024\n",
    "options2= dict(width=800,height=300,xaxis=None,yaxis=None)\n",
    "TFguit=TFCT1(guit,N)\n",
    "Spectreguit=np.abs(TFguit)\n",
    "hv.Image(Spectreguit).opts(**options2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut remarquer qu'on ne voit pas grand chose... et c'est normal si on affiche la totalité du spectrogramme. \n",
    "    Il faut avoir en tête que le son a été échantillonné à 44100Hz et qu'on effectue une analyse de Fourier sur 1024 points. Donc la première ligne du spectrogramme correspond en gros à la valeur moyenne du signal sonore sur chacune des fenêtres c'est à dire approximativement 0. La première ligne correspond à des Fréquences de l'ordre de $\\frac{44100}{1024}\\approx 43 Hz$, la deuxième ligne à des fréquences de l'ordre de 86Hz... la 21ème ligne à des fréquences de l'odre de 860Hz... autrement dit, une très grande partie de l'information de ce spectrogramme est située sur les toutes premières lignes... Pour y voir quelque chose il est préférable de zoomer, par exemple sur les 30 première lignes, où on visulise mieux le son de guitare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Spectreguitpartiel=Spectreguit[0:30,:]\n",
    "hv.Raster(Spectreguitpartiel).opts(width=800,height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(guit, rate=Fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le son de Guitare, on peut observer qu'à la fin du son, la note tenue correspond à un coefficient de Fourier important sur la ligne d'indice 10. La fréquence jouée est docn approximativement $10\\times 43=430$Hz. Il s'agit d'un La... Comme on fait une analyse que seulement 1024 points, la précision qu'on peut espérer n'est que de 43 hz. Si on veut être plus précis en fréquence, on peut faire une analyse de Fourier sur plus de points, mais on sera moins précis en temps. Vous pouvez le tester..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on zoom de la même façon sur le son de saxo, on va voir que les colonnes sont presques identiques, ceci traduit la stationnarité du son. De fait pour ce son particulier une analyse par fenêtre n'est pas la plus pertinente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Image(Spectresax[0:30,:]).opts(**options2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FTDyn(x,y,sound,TF):\n",
    "    N,Nf=np.shape(TF)\n",
    "    xx=int(x)\n",
    "    yy=int(y)\n",
    "    t=np.arange(xx*N,xx*N+N)\n",
    "    fsin=np.zeros(N)\n",
    "    fsin[yy]=1\n",
    "    sin=200*np.real(fftpack.ifft(fsin))\n",
    "    return hv.Curve(sound[xx*N:(xx+1)*N],kdims='time',vdims='pressure')\\\n",
    ".opts(width=800,height=200).redim.range(pressure=(-1,1))*hv.Curve(sin).opts(color='green')\n",
    "\n",
    "def SegDyn(x,y,sound):\n",
    "    xx=int(x)\n",
    "    yy=int(y)\n",
    "    t=np.arange(xx*N,xx*N+N)\n",
    "    C1=hv.Curve(sound,kdims='time',vdims='pressure').opts(width=800,height=200).redim.range(pressure=(-1,1))\n",
    "    C2=hv.Curve((t,sound[xx*N:xx*N+N]),kdims='time',vdims='pressure')\\\n",
    "    .opts(width=800,height=200).redim.range(pressure=(-1,1))\n",
    "    return C1*C2\n",
    "\n",
    "source1 = hv.Raster(Spectreguitpartiel,kdims = ['timewindow','freq']).opts(width=800,height=200)\n",
    "pointer = hv.streams.PointerXY(source=source1,x=8,y=20)\n",
    "#temp1=hv.DynamicMap(lambda x,y: hv.Points((x,y)).opts(size=20), streams=[pointer])\n",
    "temp=hv.DynamicMap(lambda x,y: FTDyn(x,y,guit,TFguit), streams=[pointer])\n",
    "temp2=hv.DynamicMap(lambda x,y: SegDyn(x,y,guit), streams=[pointer])\n",
    "pn.Column(source1,temp2,temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la figure précédente, en haut se trouve le spectrogramme, au milieu le son de guitare, en bas, l'extrait de son associé à la fenêtre que vous pointez sur le spectrogramme. En rouge sur le graphique du milieu est représenté l'extrait de son associé à la colonne du spectrogramme pointé par la souris. En vert sur la figure du dessous, la fréquence associé à la ligne pointé. En haut du spectrogramme, les basses fréquences, en bas les hautes fréquences. L'amplitude de la sinusoide verte, n'est pas lié au coefficient de Fourier, elle est juset constante. Le but est simplement que vous arriviez à comprendre ce que contient le spectrogramme.\n",
    "L'intensité lumineuse correspond à l'amplitude du coefficient de Fourier associé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nécessité d'un fenêtrage et d'un recouvrement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le version du spectrogramme qui a été présentée plus haut, nous avons segmenté le son sur des fenêtres disjointes. Schématiquement on a coupé violamment le signal en tranches : dans la figure suivante nous représentons deux tranches ou fenêtres d'analyse, chacune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extrait3=guit[80000:80000+20000]\n",
    "f1=np.zeros(20000)\n",
    "f1[10000:11024]=1\n",
    "d=11024\n",
    "f2=np.zeros(20000)\n",
    "f2[d:d+1024]=1\n",
    "f3=f1*0\n",
    "f3[10000:11024]=Extrait3[10000:11024]\n",
    "f4=f1*0\n",
    "f4[d:d+1024]=Extrait3[d:d+1024]\n",
    "pn.Column(hv.Curve(Extrait3,kdims='time',vdims='pressure')\\\n",
    ".opts(width=800)*hv.Curve(f3)*hv.Curve(f4).opts(color='black')\\\n",
    "          *hv.Curve(f1).opts(color='red')*hv.Curve(f2).opts(color='black'),\\\n",
    "         hv.Curve(f3[10000:11024],kdims='time',vdims='pressure').opts(width=800,color='red',title='Fenêtre rouge')\\\n",
    "         ,hv.Curve(f4[d:d+1024],kdims='time',vdims='pressure').opts(width=800,color='black',title='Fenêtre noire'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème d'un tel découpage est qu'il altère fortement le contenu fréquenciel du signal. Si vous zoomez sur les basses fréquences vous verrez que sur l'extrait de guitare long, (20000 points), les pics fréquenciels sont beaucoup mieux marqués et plus propres. Le fait d'avoir coupé brutalement le signal a un peu modifié son contenu fréquentiel. Sans rentrer dans des explications techniques, le problème vient du fait qu'extraire un signal de cette façon revient à le multiplier par une fenêtre rectangulaire (la rouge et la noire sur le diagramme plus haut). Le fait que ces fenêtres sont discontinues aux bords altère le contenu fréquentiel du signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fguit_long=fftpack.fft(Extrait3)\n",
    "fguit_short1=fftpack.fft(Extrait3[10000:11024])\n",
    "pn.Column(hv.Curve(np.abs(fguit_long),kdims='frequences',vdims='intensity').opts(width=800,title='FFT de l extrait long'),\n",
    "hv.Curve(np.abs(fguit_short1),kdims='freq',vdims='intensity').opts(width=800,title='FFT de la fenêtre rouge'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on veut se servir du spectrogramme pour effectuer des traitement sur le son, comme le vocoder ou la séparation de sources, il est fortement conseillé de \"prélever\" les petits extraits de son en appliquant ce qu'on appelle un fenêtrage, c'est-à-dire en multipliant le morceaux de son par une \"fenêtre\" d'analyse qui va fortement atténuer le signa sur les bords. Le but étant d'altérer le contenu fréquentiel le moins possible :\n",
    "https://en.wikipedia.org/wiki/Window_function\n",
    "Nous utiliserons des fenêtres de Hanning  qui est juste une fonction $\\cos^2(x)$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=np.hanning(1024)\n",
    "hv.Curve(H).opts(width=800,title='Fenêtre de Hanning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi avant de calculer les FFT de chacun des petits extraits de son sur 1024 points on va les multiplier par une fenêtre de Hanning qui va les écraser sur les bords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extrait4=Extrait3[10000:11024]\n",
    "hv.Curve(Extrait4,label='Extrait sonore').opts(width=900,height=350)*hv.Curve(H,label='Fenêtre de Hanning')\\\n",
    "*hv.Curve(H*Extrait4,label='Signal fenêtré').opts(color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tel fenêtrage a un inconvénient majeur : on perd le son au niveau du bord des fenêtres. Ici on multimlisrait le son original par une succession de fenêtre de Hanning, ce qui impliquerait d'appliquer des transformée de Fourier local au signal représenté en noir, à la la place du bleu. Zoomez pour mieux voir ce qu'il se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FenetrageBrutalHanning(son,n):\n",
    "    NS=len(son)\n",
    "    Nf=int(np.floor(NS/N))\n",
    "    h=np.hanning(n)\n",
    "    sf=0*son\n",
    "    for k in np.arange(0,Nf):\n",
    "        sf[k*N:(k+1)*N]=son[k*N:(k+1)*N]*h\n",
    "    return sf\n",
    "sf=FenetrageBrutalHanning(Extrait3,1024)\n",
    "t=np.ones(20000)\n",
    "hs=FenetrageBrutalHanning(t,1024)\n",
    "hv.Curve(Extrait3)*hv.Curve(sf).opts(width=900,color='black')*hv.Curve(hs).opts(color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter cette perte d'information, la solution la plus couramment utilisée est de construire la TFCT avec des fenêtres qui se recouvrent. C'est-à-dire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFCourtTerme(Son,N,rec):\n",
    "    H=np.hanning(N)\n",
    "    NS=len(Son)\n",
    "    Nf=int(np.floor(rec*NS/N)-rec+1)\n",
    "    TF=np.zeros((N,Nf),dtype=complex)\n",
    "    for k in range(0,Nf):\n",
    "        d=int(k*N/rec)\n",
    "        f=d+N\n",
    "        TF[:,k]=fftpack.fft(Son[d:f]*H)\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=100000\n",
    "ExtraitGuitare=guit[d:d+80*1024]\n",
    "TF=TFCourtTerme(ExtraitGuitare,1024,2)\n",
    "hv.Raster(np.abs(TF[0:50,:]))\n",
    "hv.Curve(ExtraitGuitare).opts(width=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1024\n",
    "d=int(4*N/2)\n",
    "f=d+N\n",
    "H=np.hanning(N)\n",
    "son=ExtraitGuitare[d:f]\n",
    "sonetendu=ExtraitGuitare[d-N:f+N]\n",
    "t=np.arange(d,f)\n",
    "t1=np.arange(0,N)\n",
    "t2=np.arange(N,2*N)\n",
    "hv.Curve(sonetendu).opts(width=650,height=150)\\\n",
    "*hv.Curve((t2,H)).opts(color='red')*hv.Curve((t2,son*H)).opts(color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstructionTfCT(param.Parameterized):\n",
    "    k= param.Integer(10,bounds=(1,158))\n",
    "    def view(self):\n",
    "        N=1024\n",
    "        d=int(self.k*N/2)\n",
    "        f=d+N\n",
    "        H=np.hanning(N)\n",
    "        son=ExtraitGuitare[d:f]\n",
    "        sonetendu=ExtraitGuitare[d-N:f+N]\n",
    "        t=np.arange(d,f)\n",
    "        t2=np.arange(N,2*N)\n",
    "        TFp=np.abs(TF[0:50,:])\n",
    "        TFp[:,self.k]=200\n",
    "        C1=hv.Curve((t2-N/2,H)).opts(color='green')\n",
    "        C2=hv.Curve((t2+N/2,H)).opts(color='green')\n",
    "        C3=hv.Curve((t2+N,H)).opts(color='green')\n",
    "        C4=hv.Curve((t2-N,H)).opts(color='green')\n",
    "        CT=C1*C2*C3*C4\n",
    "        return pn.Column(hv.Curve(ExtraitGuitare).opts(width=650,height=150)*hv.Curve((t,son)).opts(color='black'),\\\n",
    "                        hv.Curve(sonetendu).opts(width=650,height=150)\\\n",
    "                        *hv.Curve((t2,H)).opts(color='red')*hv.Curve((t2,son*H)).opts(color='black')*CT\\\n",
    "                         ,hv.Raster(TFp).opts(width=650,height=150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit ainsi chaque colonne en multipliant le signal par une fenêtre de Hanning. J'ai indiqué en vert les fenêtres voisines, ici avec un recouvrement de moitié. La colonne du spectogramme en blanc dans le spectrogramme est la transformée de Fourier du signal noir sur la fenêtre du milieu. Ce signal noir est la multiplication du signal original indiqué en noir sur la figure du haut, multiplié par le fenêtre de Hanning en rouge. Le signal bleu dans la figure du milieu est un zoom sur la zone noire de la figure du haut. On peut se déplacer dans le signal avec le curseur à gauche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons= ConstructionTfCT()\n",
    "pn.Row(cons.param,cons.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les choix de recouvrement sont possibles. On peut même décaler chaque fenêtre d'un point par rapport à la précédente. Et si notre objectif est d'analyser très finement un signal, il peut être pertinent de prendre un recouvrement très élevé. Notre objectif dans la suite est de reconstruire le signal à partir d'une TFCT qu'on aura évetnuellement modifiée pour effectuer des traitements, pour réaliser un vocoder puis pfaire de la séparation de sources. Les différents tests que j'ai pu faire indiquent qu'un recouvrement non pas d'une demi fenêtre mais de $\\frac{7}{8}$ de fenêtre, c'est-à-dire un décalage d'un huitième de fenêtre entre deux colonnes consécutives du spectrogramme est un bon choix pour de telles applications, c'est pourquoi c'est le choix que nous ferons par la suite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF2=TFCourtTerme(guit,1024,8)\n",
    "Spec2=np.abs(TF2)\n",
    "hv.Raster(Spec2[0:50,:]).opts(width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction d'un son à partir d'une TFCT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un des intérêt de la TFCT est qu'elle permet la reconctruction du signal original. S'il n'y avait ni recouvrement, ni fenêtrage de Hannning, l'algorithme de reconstruction serait très simple. Il suffirait de calculer les FFT inverses des colonnes de la TFCT et de les mettre bout à bout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyntheseElementaire(TF):\n",
    "    N=np.shape(TF)[0]\n",
    "    Nf=np.shape(TF)[1]\n",
    "    Son=np.zeros(N*Nf)\n",
    "    for k in range(0,Nf):\n",
    "        d=int(k*N)\n",
    "        f=d+N\n",
    "        Son[d:f]=np.real(fftpack.ifft(TF[:,k]))\n",
    "    return Son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF1=TFCT1(guit,1024)\n",
    "Sonrec=SyntheseElementaire(TF1)\n",
    "pn.Column(hv.Curve(Sonrec).opts(width=900,title='Son guitare original')\\\n",
    "         ,hv.Curve(Sonrec).opts(width=900,\\\n",
    "                                title='Son guitare reconstruit à partir d une TFCT sans recouvrement ni fenêtrage'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tant qu'on ne modifie pas la TFCT, cette méthide de reconstruction ne pose aucun problème. Pour autant, dans la pratique, on ne procède jamais ainsi. En effet recoller des petits bouts de sons traités independamment, les uns au bout des autres crée des effets sonores très désagréable dès que le recollement n'est pas parfait car on introduit des discontinuités sur le signal. Ces discontinuités, même petites induisent des hautes fréquence qui sont audibles et très désagréables. Pour palier ce problème, on ne met pas les sons élémentaires obtenus par transformée de Fourier inverses des colonnes bout à bout, on les multiplie par des fenêtres de Hanning et on les ajoute en les décalant selon le même décalage utilisé pour la construction de la TFCT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1024\n",
    "TF2=TFCourtTerme(guit,N,4)\n",
    "TF1=TFCT1(guit,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthecompar(param.Parameterized):\n",
    "    k1= param.Integer(1,bounds=(1,8))\n",
    "    k2= param.Integer(1,bounds=(1,29))\n",
    "    def view(self):\n",
    "        d1=35\n",
    "        d2=4*d1\n",
    "        N=1024\n",
    "        H=np.hanning(N)\n",
    "        t=np.arange(0,N)\n",
    "        sonel=np.real(fftpack.ifft(TF1[:,d1]))\n",
    "        sonel2=np.real(fftpack.ifft(TF2[:,d2]))*H\n",
    "        C1=hv.Curve(sonel).opts(width=650,height=150,yaxis=None,title='Son recosntruit sans recouvrement ni fenêtrage')\n",
    "        C2=hv.Curve(sonel2).opts(width=650,height=150,yaxis=None,title='Chaque nouvelle trame est multiplié par une fenêtre de Hanning')\n",
    "        sonref=np.zeros(N*8)\n",
    "        sonref[0:N]=sonel\n",
    "        for k in np.arange(1,self.k1):\n",
    "            sonel=np.real(fftpack.ifft(TF1[:,d1+k]))\n",
    "            C1=C1*hv.Curve((t+k*N,sonel)).opts(width=650)\n",
    "        for j in np.arange(1,self.k2):\n",
    "            sonel2=np.real(fftpack.ifft(TF2[:,d2+j]))\n",
    "            C2=C2*hv.Curve((t+int(j*N/4),sonel2)).opts(width=650)\n",
    "            d=int(j*N/4)\n",
    "            sonref[d:d+N]=sonref[d:d+N]+sonel2\n",
    "        C3=hv.Curve(sonref).opts(width=650,height=150,yaxis=None,title='Son reconstruit avec recouvrement et fenêtrage en ajoutant les trames fenêtrée')\n",
    "        return pn.Column(C1,C2,C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synt= Synthecompar()\n",
    "pn.Row(synt.param,synt.view)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pourrez noter qu'on reconstruit le signal parfaitement (sauf sur les bords). Le fait que la reconstruction n'est pas parfaite sur le bords n'est pas un problème car il s'agit de quelques centièmes de seconde au total.\n",
    "\n",
    "Pourtant on a multiplié par une fenêtre de Hanning deux fois \n",
    "\\begin{enumerate}\n",
    "\\item avant de caluler la FFT lors du calcul de la TFCT \n",
    "\\item et après lors de la reconstruction du son.  \n",
    "\\end{enumerate}\n",
    "Ici on n'a pas touché la TFCT donc chaque fenêtre a été multiplié par un $\\cos^4(x)$ entre le signal original et le signal recosntruit. Pourtant il n'y a aucune distorsion sur le signal en dehors des bords.\n",
    "\n",
    "Question : Expliquez ce phénomène ? \n",
    "Question : Proposez une fonction qui permet de reconstruire le signal à partir de la TFCT calculée avec recouvrement et fenêtrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
